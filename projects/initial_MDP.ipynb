{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3af27229-aa12-4c1c-8639-fd059ef2ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "\n",
    "states = [\"A\", \"B\", \"T\"]\n",
    "actions = [\"left\", \"right\"]\n",
    "\n",
    "P = {\n",
    "    \"A\": {\n",
    "        \"left\": (\"A\", 0.0),\n",
    "        \"right\": (\"B\", 0.0),\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"left\": (\"A\", 0.0),\n",
    "        \"right\": (\"T\", 1.0),\n",
    "    },\n",
    "    \"T\": {}                   #No aciton from the terminal position\n",
    "}\n",
    "\n",
    "#initialize valuse to 0\n",
    "V = {s: 0.0 for s in states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15df6a68-1b8e-4ea7-b745-08d16a8dde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(P, states, actions, gamma=0.9, theta=1e-6, max_iters=1000):\n",
    "    V = {s: 0.0 for s in states}\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        delta = 0.0\n",
    "        new_V = V.copy()\n",
    "        for s in states:\n",
    "            #if terminal action, exit from the loop\n",
    "            if s == \"T\":\n",
    "                continue\n",
    "\n",
    "            #for this state, compute value of each possible action\n",
    "            action_values = []\n",
    "            for a in actions:\n",
    "                if a not in P[s]:\n",
    "                    continue      #skip invalid actions\n",
    "                next_state, reward = P[s][a]\n",
    "                q_sa = reward + gamma*V[next_state]\n",
    "                action_values.append(q_sa)\n",
    "\n",
    "            #best action value becomes new V(s)\n",
    "            best_value = max(action_values)\n",
    "            new_V[s] = best_value\n",
    "\n",
    "            #track change for convergence check\n",
    "            delta = max(delta, abs(best_value - V[s]))\n",
    "\n",
    "        V = new_V\n",
    "        if delta < theta:\n",
    "            break\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "123c8436-0fee-48f5-b03d-e3c680836966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal State values:  {'A': 0.9, 'B': 1.0, 'T': 0.0}\n",
      "Next_state A and reward 0.0 for state A taking action left:\n",
      "q_sa:  0.81\n",
      "Next_state B and reward 0.0 for state A taking action right:\n",
      "q_sa:  0.9\n",
      "Next_state A and reward 0.0 for state B taking action left:\n",
      "q_sa:  0.81\n",
      "Next_state T and reward 1.0 for state B taking action right:\n",
      "q_sa:  1.0\n",
      "Greedy policy: {'A': 'right', 'B': 'right', 'T': None}\n"
     ]
    }
   ],
   "source": [
    "#getting optimal values and policy\n",
    "V_opt = value_iteration(P, states, actions, gamma=0.9)\n",
    "print(\"Optimal State values: \", V_opt)\n",
    "\n",
    "#derive greedy policy from V_opt\n",
    "policy = {}\n",
    "for s in states:\n",
    "    if s == \"T\":\n",
    "        policy[s] = None\n",
    "        continue\n",
    "\n",
    "    best_a = None\n",
    "    best_q = float(\"-inf\")\n",
    "    for a in actions:\n",
    "        if a not in P[s]:\n",
    "            continue\n",
    "        next_state, reward = P[s][a]\n",
    "        print(f\"Next_state {next_state} and reward {reward} for state {s} taking action {a}:\")\n",
    "        q_sa = reward + gamma*V_opt[next_state]\n",
    "        print(\"q_sa: \",q_sa)\n",
    "        if q_sa > best_q:\n",
    "            best_q = q_sa\n",
    "            best_a = a\n",
    "    policy[s] = best_a\n",
    "    \n",
    "print(\"Greedy policy:\",policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba02c2fc-a9bb-4169-bf2d-62ac5d57b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy[\"T\"] = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4d07b16-0415-4fad-968b-09132ae510be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'right', 'B': 'right', 'T': 'left'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205a8527-3b1a-40c0-9d95-f99be965ed01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_policy:  {'A': 'left'}\n",
      "test_policy:  {'A': 'right'}\n",
      "test_policy:  {'A': 'right', 'B': 'left'}\n",
      "test_policy:  {'A': 'right', 'B': 'right'}\n",
      "test_policy:  {'A': 'right', 'B': 'right', 'T': 'left'}\n",
      "test_policy:  {'A': 'right', 'B': 'right', 'T': 'right'}\n"
     ]
    }
   ],
   "source": [
    "test_policy={}\n",
    "for s in states:\n",
    "    for a in actions:\n",
    "        test_policy[s] = a\n",
    "        print(\"test_policy: \", test_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de05d6f-a848-4218-971f-3be8d6c6712b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
